<!DOCTYPE HTML>
<html lang='en'>

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
    <link rel="stylesheet" href="../frontend/subproject/subprojects.css" />
    <title>Premier League Performance Analysis</title>
    <link rel="icon" href="../icons/tab_icon.png" type="image/png">
</head>

<body>
    <div id="background-animation">
        <div class="bg-shape triangle"></div>
        <div class="bg-shape triangle-reverse"></div>
        <div class="bg-shape triangle"></div>
        <div class="bg-shape triangle-reverse"></div>
        <div class="bg-shape triangle"></div>
        <div class="bg-shape triangle-reverse"></div>
        <div class="bg-shape triangle"></div>
        <div class="bg-shape triangle-reverse"></div>
        <div class="bg-shape triangle"></div>
        <div class="bg-shape triangle-reverse"></div>
    </div>

    <div class="page-container">
        <header class="page-header">
            <h1>Premier League Performance Analysis</h1>
            <div class="nav-buttons">
                <a href="../projects.html" class="back-btn"> ← projects </a>
                <a href="../index.html" class="home-btn"> ⌂ home </a>
            </div>
        </header>

        <div class="page-content">

            <!-- overview -->
            <section>
                <h2>overview</h2>
                <p>
                    A data science project exploring whether online media presence affects soccer team performance.
                    We analyzed ~60 Premier League matches across five top teams (Arsenal, Liverpool, Manchester United, 
                    Manchester City, Chelsea) to determine if the number of news articles published between games 
                    could predict goals scored. Using Selenium web scraping for ESPN match data and The Guardian API 
                    for article counts, we built linear and polynomial regression models to test this hypothesis.
                </p>
            </section>

            <!-- data pipeline -->
            <section>
                <h2>data pipeline</h2>
                <div class="tech-tags">
                    <span>Python</span>
                    <span>Selenium</span>
                    <span>pandas</span>
                    <span>scikit-learn</span>
                    <span>matplotlib</span>
                    <span>NumPy</span>
                </div>

                <div class="features">
                    <div class="feature">
                        <strong>ESPN scraping</strong>: Selenium WebDriver navigates ESPN's team pages in headless 
                        Chrome, extracting fixtures, scores, and statistics from dynamically loaded tables using 
                        <code>pd.read_html()</code> on the page source.
                    </div>
                    <div class="feature">
                        <strong>Guardian API</strong>: RESTful calls to <code>content.guardianapis.com</code> retrieve 
                        articles matching team names within date ranges, returning headline, word count, and publication timestamp.
                    </div>
                    <div class="feature">
                        <strong>match window creation</strong>: Each game generates a time window from match end to 
                        next match start, and articles are binned into these windows to count pre-game media coverage.
                    </div>
                    <div class="feature">
                        <strong>data cleaning</strong>: Removed all rows with corrupted or lost data in important values
                        such as match dates, team names, article counts, etc. Also standardized date formats across sources
                        to make sure that the match window was perfectly matched.
                    </div>
                </div>
            </section>

            <!-- match window logic -->
            <section>
                <h2>match window logic</h2>
                <p>
                    The core challenge was attributing articles to the correct game. We defined a "match window" 
                    as the period between one game's end time and the next game's start time.
                </p>

                <div class="arch-row">
                    <span class="node">Game N ends</span>
                    <span class="arrow">→</span>
                    <span class="node">Window opens</span>
                    <span class="arrow">→</span>
                    <span class="node">Articles counted</span>
                    <span class="arrow">→</span>
                    <span class="node">Game N+1 starts</span>
                </div>

                <p>
                    This approach captures the media narrative between matches: post-match analysis of Game N 
                    and preview coverage for Game N+1. The assumption is that this combined coverage could 
                    influence team morale, fan expectations, or perceived pressure.
                </p>
            </section>

            <!-- ML models -->
            <section>
                <h2>machine learning</h2>
                <p>
                    We tested whether article count (x) could predict goals scored (y) using two regression approaches:
                </p>

                <div class="features">
                    <div class="feature">
                        <strong>linear regression</strong>: Fit a line through the data using least squares. 
                        Test MSE: 2.38, R² = -0.1087. The negative R² means predicting the mean would be more accurate.
                    </div>
                    <div class="feature">
                        <strong>polynomial regression (degree 2)</strong>: Added a quadratic term to capture 
                        non-linear relationships. Test MSE: 2.38, R² = -0.1074. No improvement over linear.
                    </div>
                    <div class="feature">
                        <strong>train/test split</strong>: 80/20 split. Training MSE was 1.5 while test MSE was 2.38, 
                        indicating the model memorizes training data but fails to generalize.
                    </div>
                </div>

                <img class="screenshot" src="../media/pl/linear.png" alt="Linear regression scatter plot">

                <img class="screenshot" src="../media/pl/polynomial.png" alt="Polynomial regression scatter plot">
            </section>

            <!-- results -->
            <section>
                <h2>results</h2>
                <p>
                    Both models performed worse than a naive baseline (predicting mean goals for every match). 
                    The negative R² scores definitively show that article count alone has no predictive power 
                    for team performance.
                </p>

                <div class="features">
                    <div class="feature">
                        <strong>no correlation found</strong>: Media coverage volume does not predict goals scored. 
                        The relationship is essentially random noise. Not a very substantial conclusion, but considering that
                        it was our first time working with real-world data and building a full ML pipeline, it was still awesome.
                    </div>
                    <div class="feature">
                        <strong>coverage follows success</strong>: More likely, successful teams generate more articles 
                        after wins, creating a lagging indicator rather than a leading one.
                    </div>
                    <div class="feature">
                        <strong>sample size limitation</strong>: 59 matches across 5 teams may be insufficient. 
                        A full season (380 matches) could reveal subtler patterns.
                    </div>
                </div>
            </section>

            <!-- future work -->
            <section>
                <h2>future work</h2>
                <div class="features">
                    <div class="feature">
                        <strong>sentiment analysis</strong>: Instead of counting articles, we could analyze their tone. 
                        For example, negative press might affect performance differently than positive coverage.
                    </div>
                    <div class="feature">
                        <strong>home vs away split</strong>: Testing if media pressure impacts home games differently than away games
                        could be interesting as crowd dynamics is the major change, assuming the pitches are all up to professional level.
                    </div>
                    <div class="feature">
                        <strong>opponent strength</strong>: Adding features like opponent league position, 
                        head-to-head history, and rest days between matches could also be substantial factors to consider.
                    </div>
                </div>
            </section>

            <!-- ethical considerations -->
            <section>
                <h2>ethical considerations</h2>
                <p>
                    If a strong relationship existed, it could imply media coverage affects player performance
                    and raise suspicious questions about whether the competition was fair before the game even started.
                    An unfair loop of rich and popular teams staying rich and popular, poorer and unpopular but talented teams
                    staying where they are.
                </p>
                <p>
                    Additionally, using article counts disadvantages smaller clubs with less media presence, potentially 
                    making predictions less accurate for them regardless of actual performance quality.
                </p>
            </section>

            <!-- construction -->
            <section>
                <h2>construction</h2>
                <p>
                    Built as a DS3000 (Foundations of Data Science) final project at Northeastern. The codebase 
                    spans three Jupyter notebooks handling scraping, cleaning, and modeling separately.
                </p>

                <div class="features">
                    <div class="feature">
                        <strong>ESPN scraping</strong>: <code>setup_driver()</code> initializes headless Chrome, 
                        <code>scrape_team_fixtures()</code> extracts tables per team, outputs 30+ team-specific DataFrames.
                    </div>
                    <div class="feature">
                        <strong>Guardian API</strong>: <code>get_guardian_articles()</code> handles making the pages, 
                        <code>get_article_data()</code> parses JSON responses into flat dictionaries.
                    </div>
                    <div class="feature">
                        <strong>window matching</strong>: Pandas datetime operations create windows, 
                        <code>pd.merge()</code> joins article counts to matches on composite keys.
                    </div>
                    <div class="feature">
                        <strong>regression</strong>: scikit-learn's <code>LinearRegression</code> and 
                        <code>PolynomialFeatures</code> with manual train/test splits and MSE/R² evaluation.
                    </div>
                </div>

                <p>
                    <strong>Source?</strong> This project was built collaboratively with William Hon, Kinsey Bellerose, 
                    and Zaid Jilla. The notebooks demonstrate the full data science pipeline from web scraping through 
                    statistical modeling and interpretation.
                </p>
            </section>

        </div>
    </div>

    <div id="mousetrailer"></div>
    <script src="../frontend/subproject/subprojects.js"></script>
</body>

</html>